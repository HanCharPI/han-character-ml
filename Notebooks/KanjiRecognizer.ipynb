{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "KanjiRecognizer.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Y3fFbT3PwQX"
      },
      "source": [
        "# Kanji Recognizer\r\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NPO2qAubQCDO"
      },
      "source": [
        "by Aiyu Kamate\r\n",
        "https://towardsdatascience.com/creating-a-japanese-handwriting-recognizer-70be12732889"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "39rbEuC0LpH9"
      },
      "source": [
        "##Installing all depenendencies needed\r\n",
        "1. Python 3.X (any python3 version should work)\r\n",
        "2. Tensorflow 2.2.0\r\n",
        "3. Keras 2.4.3\r\n",
        "4. Numpy 1.16.4\r\n",
        "6. matplotlib — newest version\r\n",
        "7. PIL — newest version\r\n",
        "8. skimage — newest version\r\n",
        "9. sklearn — newest version\r\n",
        "10. corelmltools 3.2\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MVP8uEBhMsu0"
      },
      "source": [
        "### Check python version"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "85lTz41oKspK",
        "outputId": "92018610-e470-4a30-e0da-186d07cf07d4"
      },
      "source": [
        "!python --version"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Python 3.6.9\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YWJTXeu_MwCX"
      },
      "source": [
        "### Install dependencies"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zmPRWHyrMveb"
      },
      "source": [
        "!pip install tensorflow==2.2.0\r\n",
        "!pip install keras==2.4.3\r\n",
        "!pip install numpy\r\n",
        "!pip install matplotlib\r\n",
        "!pip install Pillow\r\n",
        "!pip install scikit-image\r\n",
        "!pip install sklearn\r\n",
        "!pip install coremltools==3.2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OoAtB_tVQDti"
      },
      "source": [
        "## Preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EfwXTlUbV7wa"
      },
      "source": [
        "### Reading dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3SRlYTgT5Bn_"
      },
      "source": [
        "Reading Kanji characteres to compress it on a numpy compressed file to make it more flexible to use."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vszxds1XQIIi"
      },
      "source": [
        "import struct, os\r\n",
        "from PIL import Image\r\n",
        "import numpy as np\r\n",
        "\r\n",
        "# Hiragana character to filter out images\r\n",
        "label = [\"あ\", \"い\", \"う\", \"え\", \"お\", \"か\", \"が\",  \"き\", \"ぎ\",\r\n",
        "         \"く\", \"ぐ\", \"け\", \"げ\", \"こ\", \"ご\", \"さ\", \"ざ\", \"し\",\r\n",
        "         \"じ\", \"す\", \"ず\", \"せ\", \"ぜ\", \"そ\", \"ぞ\", \"た\", \"だ\",\r\n",
        "         \"ち\", \"ぢ\", \"つ\", \"づ\", \"て\", \"で\", \"と\", \"ど\", \"な\",\r\n",
        "         \"に\", \"ぬ\", \"ね\", \"の\", \"は\", \"ば\", \"ぱ\", \"ひ\", \"び\",\r\n",
        "         \"ぴ\", \"ふ\", \"ぶ\", \"ぷ\", \"へ\", \"べ\", \"ぺ\", \"ほ\", \"ぼ\",\r\n",
        "         \"ぽ\", \"ま\", \"み\", \"む\", \"め\", \"も\", \"や\", \"ゆ\", \"よ\",\r\n",
        "         \"ら\", \"り\", \"る\", \"れ\", \"ろ\", \"わ\", \"を\", \"ん\", \"っ\",\r\n",
        "         \"ゃ\", \"ゅ\", \"ょ\"]\r\n",
        "\r\n",
        "def string_unicode_to_han(unicode):\r\n",
        "    han_unicode = '\\\\u{}'.format(unicode)\r\n",
        "    return han_unicode.encode('ascii').decode('unicode-escape')\r\n",
        "\r\n",
        "def file_path_narray(filepath):\r\n",
        "    im = Image.open(filepath)\r\n",
        "    return im.convert('L')\r\n",
        "\r\n",
        "def read_kanji():\r\n",
        "    \"\"\"\r\n",
        "    881 - kanji excluding hiragana characters\r\n",
        "    161 - images by writers\r\n",
        "    127 - width\r\n",
        "    128 - height\r\n",
        "    \"\"\"\r\n",
        "    kanji = np.zeros([881, 161, 127, 128], dtype=np.uint8) \r\n",
        "    foldername = \"../dataset/ETL8G/\"\r\n",
        "    i = 0\r\n",
        "    print(\"Reading images...\")\r\n",
        "    for folder in os.scandir(foldername):\r\n",
        "        # Decode unicode to han character\r\n",
        "        han_char = string_unicode_to_han(folder.name[2:])\r\n",
        "\r\n",
        "        if(han_char not in label):\r\n",
        "            j = 0\r\n",
        "            for file in os.scandir(folder.path):\r\n",
        "                if file.name != \".char.txt\":\r\n",
        "                    # Convert file to Pillow image and then to numpy array\r\n",
        "                    iL = file_path_narray(file.path)\r\n",
        "                    kanji[i, j] =  np.array(iL)\r\n",
        "                    j += 1\r\n",
        "            i += 1\r\n",
        "    print(\"Finished reading images\")\r\n",
        "    # Finish compressing kanji dataset\r\n",
        "    print(\"Compressing images...\")\r\n",
        "    np.savez_compressed(\"kanji.npz\", kanji)\r\n",
        "    print(\"Finished compressing\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sf42j-PiRi2L"
      },
      "source": [
        "read_kanji()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SzMeIMp1b1Mf"
      },
      "source": [
        "### Converting data to training and test labels/images"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MZ_GGB0wcH3l"
      },
      "source": [
        "import skimage.transform\r\n",
        "import numpy as np\r\n",
        "from sklearn.model_selection import train_test_split\r\n",
        "\r\n",
        "kanji = np.load(\"kanji.npz\")['arr_0'].reshape([-1, 63, 64]).astype(np.float32)\r\n",
        "\r\n",
        "kanji = kanji/np.max(kanji) # make the numbers range from 0 to 1\r\n",
        "\r\n",
        "# 51 is the number of different katakana (3 are duplicates so in the end there are 48 classes), 1411 writers.\r\n",
        "train_images = np.zeros([51 * 1411, 48, 48], dtype=np.float32)\r\n",
        "\r\n",
        "for i in range(51 * 1411): # change the image size to 48*48\r\n",
        "    train_images[i] = skimage.transform.resize(kanji[i], (48, 48))\r\n",
        "\r\n",
        "arr = np.arange(51) # create labels\r\n",
        "train_labels = np.repeat(arr, 1411)\r\n",
        "\r\n",
        "# In the actual code, I combined the duplicate classes here and had 48 classes in the end\r\n",
        "\r\n",
        "# split the images/labels to train and test\r\n",
        "train_images, test_images, train_labels, test_labels = train_test_split(train_images, train_labels, test_size=0.2)\r\n",
        "\r\n",
        "np.savez_compressed(\"kanji_train_images.npz\", train_images)\r\n",
        "np.savez_compressed(\"kanji_train_labels.npz\", train_labels)\r\n",
        "np.savez_compressed(\"kanji_test_images.npz\", test_images)\r\n",
        "np.savez_compressed(\"kanji_test_labels.npz\", test_labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cf46lg2mUwS_"
      },
      "source": [
        "### Visualizing training images"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MFKXEWbkU1fq"
      },
      "source": [
        "import matplotlib.pyplot as plt\r\n",
        "plt.figure(figsize=(6,6)).patch.set_facecolor('#000000')\r\n",
        "for i in range(25):\r\n",
        "    plt.subplot(5,5,i+1)\r\n",
        "    plt.xticks([])\r\n",
        "    plt.yticks([])\r\n",
        "    plt.grid(False)\r\n",
        "    plt.imshow(train_images[i], cmap=plt.cm.binary)\r\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}